{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525a2a4f-68e1-43be-8a7b-605ddab5229f",
   "metadata": {},
   "source": [
    "# Data Processing - Experiment 4: IT SynthTone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63667ac-c6c6-4038-9977-dbeacd1273ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e67c5db-3211-49f3-9ae6-e77d6f9cb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sm\n",
    "from glob import glob\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "def rescale_ioi(ioi):\n",
    "    \"\"\"\n",
    "    Calculates location of an IOI on a 0-100 scale. Appears in the manuscript\n",
    "    as Equation 1.\n",
    "\n",
    "    This conversion assumes that 0=275ms and 100=1100ms, given\n",
    "    that a 275 ms IOI is a rate twice as fast as the metronome and a 1100 ms\n",
    "    IOI is a rate half as fast as the metronome.\n",
    "    \"\"\"\n",
    "    ioi = 100 * np.log(1100 / ioi) / np.log(1100 / 275) \n",
    "    return np.round(ioi, 5)\n",
    "\n",
    "# Define and find file paths\n",
    "DATA_PATH = '../data/'\n",
    "SAVEFILE = '../data/response_data.csv'\n",
    "\n",
    "# Define levels of conditions\n",
    "IOI_LEVELS = [1000, 918, 843, 774, 710, 652, 599, 550, 504, 463, 425, 390, 358, 329, 302]\n",
    "TEMPO_BINS = [(1000, 918, 843), (774, 710, 652), (599, 550, 504), (463, 425, 390), (358, 329, 302)]\n",
    "PITCH_LEVELS = [2, 3, 4, 5, 6, 7]\n",
    "LOUDNESS_LEVELS = [0, 1, 2]\n",
    "\n",
    "# Calculate ground-truth ratings for each IOI and tempo range\n",
    "CORRECT_RATINGS = [rescale_ioi(ss.gmean(iois)) for iois in TEMPO_BINS]\n",
    "CORRECT_RATINGS_FULL = [rescale_ioi(ioi) for ioi in IOI_LEVELS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978e942-9525-4bcd-9e58-a3ed195ebb5b",
   "metadata": {},
   "source": [
    "### Load Raw Data\n",
    "\n",
    "Pavlovia saves each person's data to a separate CSV file. Here we use glob to find all the data files. We then read each data file with Pandas, check to make sure it's a complete session (i.e., it has an \"ending\" event), and append it to a single dataframe containing everyone's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be460aa-a46c-4136-b1fb-f9b890058c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = np.array(glob(DATA_PATH + 'I*.csv'))\n",
    "df = []\n",
    "for f in datafiles:\n",
    "    d = pd.read_csv(f)\n",
    "    if 'event' in d and d.event.iloc[-1] == 'ending':\n",
    "        df.append(d)\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f05917-7a1e-4eac-ad51-ef4232aa97dc",
   "metadata": {},
   "source": [
    "### Process Main Task\n",
    "\n",
    "Get data frames containing only tone presentations and responses, respectively. Each trial produces one presentation event and one response event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2b2ff8-fe0a-4c27-b88e-33005d9b6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_rows = df[df['event'] == 'tones'].index\n",
    "pres = df.iloc[pres_rows]\n",
    "resp = df.iloc[pres_rows + 1]\n",
    "pres = pres.reset_index(drop=True)\n",
    "resp = resp.reset_index(drop=True)\n",
    "if not np.all(resp.event == 'response'):\n",
    "    raise ValueError('Non-response event included in response dataframe.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf20c9-ae13-4d2c-9e69-0c69e519518a",
   "metadata": {},
   "source": [
    "Next, convert conditions and responses from floats to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce724f28-34db-4aef-aec0-19a2eb7ccd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in ('pitch', 'ioi', 'loudness'):\n",
    "    pres.loc[:, colname] = pres[colname].astype(int)\n",
    "for colname in ('pitch', 'ioi', 'loudness', 'response'):\n",
    "    resp.loc[:, colname] = resp[colname].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e9ac8-b962-461a-9123-f94d00cc7eb8",
   "metadata": {},
   "source": [
    "Add a column containing ground truth tempo ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56bd8e2-0b25-4b2d-80e0-e38869391fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_map = dict()\n",
    "for i, iois in enumerate(TEMPO_BINS):\n",
    "    for ioi in iois:\n",
    "        tempo_map[ioi] = i + 1\n",
    "pres = pres.assign(tempo=[tempo_map[ioi] for ioi in pres['ioi']])\n",
    "pres = pres.assign(true_score=rescale_ioi(pres['ioi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbb6be-1d5e-4ef1-9a8f-4b3e1edc003a",
   "metadata": {},
   "source": [
    "Finally, merge presentation and response data back into one data frame with a single row per trial. This will be easier to analyze than having presentation and response data on separate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249214d8-b0bb-450c-9646-fa47af54a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest from presentation and response events\n",
    "pres = pres[['subject', 'first_type', 'pitch', 'ioi', 'tempo', 'loudness', \n",
    "             'type', 'true_score']]\n",
    "resp = resp[['response', 'rt']]\n",
    "\n",
    "# Merge presentation and response data\n",
    "data = pd.merge(pres, resp, left_index=True, right_index=True)\n",
    "\n",
    "# Addd column containing the difference between the correct and actual response\n",
    "data = data.assign(error=data.response - data.true_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56af396-66ec-4671-8157-9bb21dfebeb7",
   "metadata": {},
   "source": [
    "### Additional Scoring\n",
    "\n",
    "Initialize arrays for all the new columns we will be adding to the data frame. An asterisk in the comment indicates that the value is identical for all trials within a given subject; otherwise the score will vary within subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da2283a-44de-43a7-8af0-ef3d12b2e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "block = np.zeros(len(data), dtype=int)  # Block number of the trial\n",
    "trial = np.zeros(len(data), dtype=int)  # Trial number within the session\n",
    "\n",
    "# Headphone test scores\n",
    "test_correct = np.zeros(len(data), dtype=int)  # Questions answered correctly (*)\n",
    "test_incorrect = np.zeros(len(data), dtype=int)  # Questions answered incorrectly (*)\n",
    "test_skipped = np.zeros(len(data), dtype=int)  # Questions skipped (*)\n",
    "\n",
    "# Performance criteria\n",
    "extremes = np.zeros(len(data), dtype=float)  # Trials on which they answered 0, 50, or 100 (*)\n",
    "corr = np.zeros(len(data), dtype=float)  # Pearson r correlation between each person's ratings and the ground truth (*)\n",
    "\n",
    "# Parameters and scores relating to the subject-specific IOI-to-rating linear models\n",
    "slope = np.zeros(len(data), dtype=float)  # Slope of the model (*)\n",
    "intercept = np.zeros(len(data), dtype=float)  # Intercept of the model (*)\n",
    "resid = np.zeros(len(data), dtype=float)  # Residual tempo rating on each trial\n",
    "cooks = np.zeros(len(data), dtype=float)  # Cook's distance for the response on each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376f033c-1729-4336-a5fa-74cc47884b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define block numbers and trial numbers (these will be the same for each participant)\n",
    "block_numbers = np.concatenate([[x for _ in range(30)] for x in range(6)])\n",
    "trial_numbers = np.arange(1, 181)\n",
    "\n",
    "# Identify which rows come from the headphone test\n",
    "test_tones_mask = df.event == 'headphone_test_tones'\n",
    "test_response_mask = df.event == 'headphone_test_response'\n",
    "\n",
    "for subj in np.unique(data.subject):\n",
    "\n",
    "    # Identify events from current subject\n",
    "    subj_mask = data.subject == subj\n",
    "    subj_mask_full = df.subject == subj\n",
    "    \n",
    "    # Label trials with the blocks they are from\n",
    "    block[subj_mask] = block_numbers\n",
    "    trial[subj_mask] = trial_numbers\n",
    "    \n",
    "    # Isolate headphone test presentation and response data\n",
    "    testpres = df.loc[subj_mask_full & test_tones_mask, :].reset_index()\n",
    "    testresp = df.loc[subj_mask_full & test_response_mask, :].reset_index()\n",
    "    \n",
    "    # Convert key codes for responses to 1, 2, and 3. Then determine whether 1, 2, or 3 was the correct answer \n",
    "    # based on the position of 'S' in the stimulus file name\n",
    "    testresp = testresp.assign(response=np.array(testresp.key_press, dtype=int) - 48,\n",
    "                              answer=[s.find('S') - 28 for s in testpres.stimulus])\n",
    "    \n",
    "    # Score headphone test trials by comparing responses to the correct answers\n",
    "    testresp = testresp.assign(correct=testresp.response == testresp.answer,\n",
    "                              incorrect=(testresp.response != testresp.answer) & (testresp.response > 0),\n",
    "                              skipped=testresp.response == 0)\n",
    "    test_correct[subj_mask] = testresp.correct.sum()\n",
    "    test_incorrect[subj_mask] = testresp.incorrect.sum() \n",
    "    test_skipped[subj_mask] = testresp.skipped.sum()\n",
    "\n",
    "    # Count number of times the participant responded 0|50|100\n",
    "    score = np.sum(np.isin(data.loc[subj_mask, 'response'], (0, 50, 100)))\n",
    "    extremes[subj_mask] = score\n",
    "\n",
    "    # Calculate correlation between participant's responses and actual IOI\n",
    "    score = ss.pearsonr(data.loc[subj_mask, 'true_score'], data.loc[subj_mask, 'response'])[0]\n",
    "    corr[subj_mask] = score\n",
    "\n",
    "    # Fit model of how the paricipant mapped tempo onto the scale\n",
    "    fit = sm.OLS(data.loc[subj_mask, 'response'], \n",
    "                 sm.add_constant(np.log(data.loc[subj_mask, 'ioi']))).fit()\n",
    "\n",
    "    # Identify outlier trials based on Cook's distance\n",
    "    cooks[subj_mask] = OLSInfluence(fit).summary_frame().cooks_d\n",
    "\n",
    "    # Refit model without outliers\n",
    "    refit_mask = subj_mask & (cooks <= 4 / subj_mask.sum())\n",
    "    fit = sm.OLS(data.loc[refit_mask, 'response'],\n",
    "                sm.add_constant(np.log(data.loc[refit_mask, 'ioi']))).fit()\n",
    "    intercept[subj_mask] = fit.params[0]\n",
    "    slope[subj_mask] = fit.params[1]\n",
    "\n",
    "    # Save model fit\n",
    "    resid[subj_mask] = data.loc[subj_mask, 'response'] - \\\n",
    "        fit.predict(sm.add_constant(np.log(data.loc[subj_mask, 'ioi'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1631a78-0583-4bf9-a0b3-48e60c138e4f",
   "metadata": {},
   "source": [
    "Add all the new columns to the data frame. This will be our final, processed version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9cbfb2c-8cfe-49bb-ac64-f23ee2c35d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'block'] = block\n",
    "data.loc[:, 'trial'] = trial\n",
    "data.loc[:, 'test_correct'] = test_correct\n",
    "data.loc[:, 'test_incorrect'] = test_incorrect\n",
    "data.loc[:, 'test_skipped'] = test_skipped\n",
    "data.loc[:, 'extreme_responses'] = extremes\n",
    "data.loc[:, 'pearsonr'] = corr\n",
    "data.loc[:, 'intercept'] = intercept\n",
    "data.loc[:, 'slope'] = slope\n",
    "data.loc[:, 'residual'] = resid\n",
    "data.loc[:, 'cooks'] = cooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655fc7b-d02f-4d5d-b389-13153a5bae79",
   "metadata": {},
   "source": [
    "### Save Processed Data\n",
    "\n",
    "Save the cleaned and processed version of the data to a CSV. This is the file we will load to perform analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98614a9-e45d-48af-af59-b60e21c5f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(SAVEFILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
