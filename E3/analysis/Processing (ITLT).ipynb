{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0023ead0-04c2-4959-972a-42d50f5595c2",
   "metadata": {},
   "source": [
    "# Data Processing - Experiment 3: IT LongTone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecad987-c93e-4f1c-a91d-2590b338d36a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811ed315-5052-4ca1-9f98-cdc88eca343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sm\n",
    "from glob import glob\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "def rescale_ioi(ioi):\n",
    "    \"\"\"\n",
    "    Calculates location of an IOI on a 0-100 scale. Appears in the manuscript\n",
    "    as Equation 1.\n",
    "\n",
    "    This conversion assumes that 0=275ms and 100=1100ms, given\n",
    "    that a 275 ms IOI is a rate twice as fast as the metronome and a 1100 ms\n",
    "    IOI is a rate half as fast as the metronome.\n",
    "    \"\"\"\n",
    "    ioi = 100 * np.log(1100 / ioi) / np.log(1100 / 275) \n",
    "    return np.round(ioi, 5)\n",
    "\n",
    "# Define and find file paths\n",
    "DATA_PATH = '../data/'\n",
    "SAVEFILE = '../data/response_data.csv'\n",
    "TAP_SAVEFILE = '../data/tap_data.csv'\n",
    "\n",
    "# Define levels of conditions\n",
    "IOI_LEVELS = [1000, 918, 843, 774, 710, 652, 599, 550, 504, 463, 425, 390, 358, 329, 302]\n",
    "TEMPO_BINS = [(1000, 918, 843), (774, 710, 652), (599, 550, 504), (463, 425, 390), (358, 329, 302)]\n",
    "PITCH_LEVELS = [2, 3, 4, 5, 6, 7]\n",
    "LOUDNESS_LEVELS = [0, 1, 2]\n",
    "\n",
    "# Calculate ground-truth ratings for each IOI and tempo range\n",
    "CORRECT_RATINGS = [rescale_ioi(ss.gmean(iois)) for iois in TEMPO_BINS]\n",
    "CORRECT_RATINGS_FULL = [rescale_ioi(ioi) for ioi in IOI_LEVELS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f30b9-32fa-4477-8691-d479521d161d",
   "metadata": {},
   "source": [
    "### Load Raw Data\n",
    "\n",
    "Pavlovia saves each person's data to a separate CSV file. Here we use glob to find all the data files. We then read each data file with Pandas, check to make sure it's a complete session (i.e., it has an \"ending\" event), and append it to a single dataframe containing everyone's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d56b770-43c5-47e9-a43f-495b72e80696",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = np.array(glob(DATA_PATH + 'I*.csv'))\n",
    "df = []\n",
    "for f in datafiles:\n",
    "    d = pd.read_csv(f)\n",
    "    # Ensure that the session is complete\n",
    "    if 'event' in d and d.event.iloc[-1] == 'ending':\n",
    "        df.append(d)\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7445e6-d65f-4324-a28e-e2f784cb1461",
   "metadata": {},
   "source": [
    "### Process Spontaneous Motor Tempo Task\n",
    "\n",
    "Separate out the spontaneous motor tempo task from each participant into a new tap_data data frame with one row per subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dae26d4-b2d9-4b8d-b926-5372874ad2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data = df[df.event == 'tapping_test']\n",
    "tap_data = tap_data.rename(columns={'rt': 'tap_times'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b218defe-755b-4130-b449-d420bb960f4b",
   "metadata": {},
   "source": [
    "Convert the lists of key presses and tap times from strings into lists of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edc1c68-bbe9-4b8e-8df0-5d29580180d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_data['key_press'] = [[int(y) for y in x.split(',')] \n",
    "                         if type(x) == str else x for x in tap_data.key_press]\n",
    "tap_data['tap_times'] = [[int(y) for y in x.split(',')] \n",
    "                         if type(x) == str else x for x in tap_data.tap_times]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd01076-4be1-4918-8db1-3902033685cb",
   "metadata": {},
   "source": [
    "Clean invalid key presses from the spontaneous rate tapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce59a505-3bf1-43ca-aa0f-c3d81457804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_key_presses = []\n",
    "valid_tap_times = []\n",
    "for i in tap_data.index:\n",
    "    if isinstance(tap_data.loc[i, 'key_press'], float):\n",
    "        if np.isnan(tap_data.loc[i, 'key_press']):\n",
    "            tap_data.loc[i, 'key_press'] = [[np.nan]]\n",
    "            tap_data.loc[i, 'tap_times'] = [[np.nan]]\n",
    "        else:\n",
    "            tap_data.loc[i, 'key_press'] = [[int(tap_data.loc[i, 'key_press'])]]\n",
    "            tap_data.loc[i, 'tap_times'] = [[int(tap_data.loc[i, 'tap_times'])]]\n",
    "    fj_mask = np.in1d(tap_data.loc[i, 'key_press'], [70, 74])\n",
    "    valid_key_presses.append(np.array(tap_data.loc[i, 'key_press'])[fj_mask])\n",
    "    valid_tap_times.append(np.array(tap_data.loc[i, 'tap_times'])[fj_mask])\n",
    "tap_data['valid_key_press'] = valid_key_presses\n",
    "tap_data['valid_tap_times'] = valid_tap_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4cb91d-9849-4f32-925b-3df35673ccaf",
   "metadata": {},
   "source": [
    "Calculate median inter-tap intervals (NaN if tapped 3 or fewer times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99eac9d-f4e4-4742-8549-329b4d04aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "itis = [np.median(np.diff(times)) if len(times) > 3 else np.nan \n",
    "        for times in tap_data.valid_tap_times]\n",
    "tap_data['pref_rate'] = itis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f1459-999a-40c6-8838-67e6a52385a1",
   "metadata": {},
   "source": [
    "### Process Main Task\n",
    "\n",
    "Get data frames containing only tone presentations and responses, respectively. Each trial produces one presentation event and one response event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb2cb0e-63fe-4feb-97f8-fb10b792d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_rows = df[df['event'] == 'tones'].index\n",
    "pres = df.iloc[pres_rows]\n",
    "resp = df.iloc[pres_rows + 1]\n",
    "pres.reset_index(drop=True, inplace=True)\n",
    "resp.reset_index(drop=True, inplace=True)\n",
    "if not np.all(resp.event == 'response'):\n",
    "    raise ValueError('Non-response event included in response dataframe.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810a2cd-a1ff-4777-9fd8-fa178ec13f9a",
   "metadata": {},
   "source": [
    "Next, read the stimulus file names to determine the pitch, IOI, and loudness of each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6649cf-2523-474b-81b1-d365c36aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = pres.assign(pitch=[int(s[17]) for s in pres['stimulus']],\n",
    "                   ioi=[int(s[19:-6]) for s in pres['stimulus']],\n",
    "                   loudness=[int(s[-5]) for s in pres['stimulus']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e3865-c9b4-498a-befd-dded4ebd3e9d",
   "metadata": {},
   "source": [
    "Add a column containing ground truth tempo ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e34ce1-3399-4890-88b2-282603ea4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_map = dict()\n",
    "for i, iois in enumerate(TEMPO_BINS):\n",
    "    for ioi in iois:\n",
    "        tempo_map[ioi] = i + 1\n",
    "pres = pres.assign(tempo=[tempo_map[ioi] for ioi in pres['ioi']])\n",
    "pres = pres.assign(true_score=rescale_ioi(pres['ioi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2764661-45a6-43e1-bc78-a7d108687bc9",
   "metadata": {},
   "source": [
    "Finally, merge presentation and response data back into one data frame with a single row per trial. This will be easier to analyze than having presentation and response data on separate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f1649a8-f03e-4b90-857b-e972ed3d49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of interest from presentation and response events\n",
    "pres = pres[['subject', 'pitch', 'ioi', 'tempo', 'loudness', \n",
    "             'tap_condition', 'key_press', 'rt', 'true_score']]\n",
    "resp = resp[['response', 'rt']]\n",
    "\n",
    "# Rename overlapping column name\n",
    "pres.rename(columns={'rt': 'tap_times'}, inplace=True)\n",
    "\n",
    "# Convert tapping information from strings to lists\n",
    "pres['key_press'] = [[int(y) for y in x.split(',')] \n",
    "                     if type(x) == str else x for x in pres.key_press]\n",
    "pres['tap_times'] = [[int(y) for y in x.split(',')] \n",
    "                     if type(x) == str else x for x in pres.tap_times]\n",
    "    \n",
    "# Merge presentation and response data\n",
    "data = pd.merge(pres, resp, left_index=True, right_index=True)\n",
    "\n",
    "# Addd column containing the difference between the correct and actual response\n",
    "data = data.assign(error=data.response - data.true_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d991d4-422a-4c89-910c-b40a7901df67",
   "metadata": {},
   "source": [
    "### Additional Scoring\n",
    "\n",
    "Initialize arrays for all the new columns we will be adding to the data frame. An asterisk in the comment indicates that the value is identical for all trials within a given subject; otherwise the score will vary within subjects. Scores that only have one value per participant will also be included in the tap_data dataset (which only includes one row per subject)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800303e2-db1a-46ea-a23e-669ecd8b402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "block = np.zeros(len(data), dtype=int)\n",
    "trial = np.zeros(len(data), dtype=int)\n",
    "\n",
    "# Headphone test scores (*)\n",
    "test_correct = np.zeros(len(data), dtype=int)\n",
    "test_correct2 = np.zeros(len(tap_data), dtype=int)\n",
    "test_incorrect = np.zeros(len(data), dtype=int)\n",
    "test_incorrect2 = np.zeros(len(tap_data), dtype=int)\n",
    "test_skipped = np.zeros(len(data), dtype=int)\n",
    "test_skipped2 = np.zeros(len(tap_data), dtype=int)\n",
    "\n",
    "# Trials on which they answered 0, 50, or 100 (*)\n",
    "extremes = np.zeros(len(data), dtype=float)  \n",
    "extremes2 = np.zeros(len(tap_data), dtype=float)\n",
    "\n",
    "# Pearson r correlation between each person's ratings and the ground truth (*)\n",
    "corr = np.zeros(len(data), dtype=float)\n",
    "corr2 = np.zeros(len(tap_data), dtype=float)\n",
    "\n",
    "# Slope and intercept of subject-specific IOI-to-rating linear models (*)\n",
    "intercept = np.zeros(len(data), dtype=float)\n",
    "intercept2 = np.zeros(len(tap_data), dtype=float)\n",
    "slope = np.zeros(len(data), dtype=float)\n",
    "slope2 = np.zeros(len(tap_data), dtype=float)\n",
    "\n",
    "# Residual tempo rating and cook's distance for the response on each trial\n",
    "resid = np.zeros(len(data), dtype=float)\n",
    "cooks = np.zeros(len(data), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ab41f-5b1e-473e-ba77-d79378c52a66",
   "metadata": {},
   "source": [
    "Perform a variety of data processing for each participant. Exclusion-related scoring includes marking the headphone test, counting how many times the participant gave an extreme response (0|50|100), and calculating the correlation between their responses and the actual tempo. We then fit the subject-specific models relating IOIs to raw ratings (Equation 3 in the manuscript) and calculate residual tempo ratings for all trials (Equation 4 in the manuscript)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a8079fa-dc0a-474c-ad13-24a9b35b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define block numbers and trial numbers (these will be the same for each participant)\n",
    "block_numbers = np.concatenate([[x for _ in range(30)] for x in range(3)])\n",
    "trial_numbers = np.arange(1, 91)\n",
    "\n",
    "# Identify which rows come from the headphone test\n",
    "test_tones_mask = df.event == 'headphone_test_tones'\n",
    "test_response_mask = df.event == 'headphone_test_response'\n",
    "\n",
    "# Calculate performance metrics and regression model for each participant\n",
    "for subj in np.unique(data.subject):\n",
    "\n",
    "    # Identify events from current subject\n",
    "    subj_mask = data.subject == subj\n",
    "    subj_mask_full = df.subject == subj\n",
    "    subj_mask_tapdata = tap_data.subject == subj\n",
    "    \n",
    "    # Label trials with the blocks they are from\n",
    "    block[subj_mask] = block_numbers\n",
    "    trial[subj_mask] = trial_numbers\n",
    "    \n",
    "    # Isolate headphone test presentation and response data\n",
    "    testpres = df.loc[subj_mask_full & test_tones_mask, :].reset_index()\n",
    "    testresp = df.loc[subj_mask_full & test_response_mask, :].reset_index()\n",
    "    \n",
    "    # Convert key codes for responses to 1, 2, and 3. Then determine whether 1, 2, or 3 was the correct answer \n",
    "    # based on the position of 'S' in the stimulus file name\n",
    "    testresp = testresp.assign(response=np.array(testresp.key_press, dtype=int) - 48,\n",
    "                              answer=[s.find('S') - 28 for s in testpres.stimulus])\n",
    "    \n",
    "    # Score headphone test trials by comparing responses to the correct answers\n",
    "    testresp = testresp.assign(correct=testresp.response == testresp.answer,\n",
    "                              incorrect=(testresp.response != testresp.answer) & (testresp.response > 0),\n",
    "                              skipped=testresp.response == 0)\n",
    "    test_correct[subj_mask] = testresp.correct.sum()\n",
    "    test_correct2[subj_mask_tapdata] = testresp.correct.sum()\n",
    "    test_incorrect[subj_mask] = testresp.incorrect.sum() \n",
    "    test_incorrect2[subj_mask_tapdata] = testresp.incorrect.sum() \n",
    "    test_skipped[subj_mask] = testresp.skipped.sum()\n",
    "    test_skipped2[subj_mask_tapdata] = testresp.skipped.sum()\n",
    "\n",
    "    # Count number of times the participant responded 0|50|100\n",
    "    score = np.sum(np.isin(data.loc[subj_mask, 'response'], (0, 50, 100)))\n",
    "    extremes[subj_mask] = score\n",
    "    extremes2[subj_mask_tapdata] = score\n",
    "\n",
    "    # Calculate correlation between participant's responses and true relative tempo\n",
    "    score = ss.pearsonr(data.loc[subj_mask, 'true_score'], data.loc[subj_mask, 'response'])[0]\n",
    "    corr[subj_mask] = score\n",
    "    corr2[subj_mask_tapdata] = score\n",
    "\n",
    "    # Fit model of how the paricipant mapped tempo onto the scale\n",
    "    fit = sm.OLS(data.loc[subj_mask, 'response'], \n",
    "                sm.add_constant(np.log2(550 / data.loc[subj_mask, 'ioi']))).fit()\n",
    "\n",
    "    # Identify outlier trials based on Cook's distance\n",
    "    cooks[subj_mask] = OLSInfluence(fit).summary_frame().cooks_d\n",
    "\n",
    "    # Refit model without outliers\n",
    "    refit_mask = subj_mask & (cooks <= 4 / subj_mask.sum())\n",
    "    fit = sm.OLS(data.loc[refit_mask, 'response'],\n",
    "                sm.add_constant(np.log2(550 / data.loc[refit_mask, 'ioi']))).fit()\n",
    "    intercept[subj_mask] = fit.params[0]\n",
    "    intercept2[subj_mask_tapdata] = fit.params[0]\n",
    "    slope[subj_mask] = fit.params[1]\n",
    "    slope2[subj_mask_tapdata] = fit.params[1]\n",
    "\n",
    "    # Calculate residual tempo ratings\n",
    "    resid[subj_mask] = data.loc[subj_mask, 'response'] - \\\n",
    "        fit.predict(sm.add_constant(np.log2(550 / data.loc[subj_mask, 'ioi'])))\n",
    "\n",
    "# Mark trials as tapping type NTI (0), TI-NT (1), or TI-YT (2) based on whether the participant tapped to the repeating tone\n",
    "data.loc[:, 'tapped'] = np.array([isinstance(x, (str, list)) for x in data.key_press])\n",
    "data.loc[:, 'tap_type'] = data.tap_condition.astype(int) + (data.tap_condition & data.tapped).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26399a-8e87-4fa5-94a1-5c9e935abc6b",
   "metadata": {},
   "source": [
    "Add all the new columns to the data frames. These will be our final, processed versions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd13bea-6a39-4574-8d10-5096e7a7d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'block'] = block\n",
    "data.loc[:, 'trial'] = trial\n",
    "data.loc[:, 'test_correct'] = test_correct\n",
    "tap_data.loc[:, 'test_correct'] = test_correct2\n",
    "data.loc[:, 'test_incorrect'] = test_incorrect\n",
    "tap_data.loc[:, 'test_incorrect'] = test_incorrect2\n",
    "data.loc[:, 'test_skipped'] = test_skipped\n",
    "tap_data.loc[:, 'test_skipped'] = test_skipped2\n",
    "data.loc[:, 'extreme_responses'] = extremes\n",
    "tap_data.loc[:, 'extreme_responses'] = extremes2\n",
    "data.loc[:, 'pearsonr'] = corr\n",
    "tap_data.loc[:, 'pearsonr'] = corr2\n",
    "data.loc[:, 'intercept'] = intercept\n",
    "tap_data.loc[:, 'intercept'] = intercept2\n",
    "data.loc[:, 'slope'] = slope\n",
    "tap_data.loc[:, 'slope'] = slope2\n",
    "data.loc[:, 'residual'] = resid\n",
    "data.loc[:, 'cooks'] = cooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcaf46-fd18-4b71-a5f1-d73fdd6ad779",
   "metadata": {},
   "source": [
    "### Save Processed Data\n",
    "\n",
    "Save the cleaned and processed version of the data to a CSV. These are the files we will load to perform analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ac766c-a617-4be1-ac3b-9ecbcd5488f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(SAVEFILE, index=False)\n",
    "tap_data.to_csv(TAP_SAVEFILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
